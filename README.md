# ATS-Tailor: Resume Optimization Assistant

**Tailor your resume to any job description in minutes with AI-powered suggestions.**

A privacy-first tool that analyzes your resume against job descriptions and provides actionable edits to maximize ATS compatibility.

---

## âœ¨ Features

- ğŸ“Š **ATS Scoring** - Get a 0-100 score with detailed breakdown
- ğŸ¯ **Gap Detection** - Identifies missing skills and weak evidence
- âœï¸ **AI Suggestions** - LLM-powered bullet rewrites (Ollama, OpenAI, Claude, Gemini)
- ğŸ”’ **Privacy-First** - Runs 100% locally by default
- âš¡ **Fast** - Analysis in <10 seconds

---

## ğŸš€ Quick Start

### 1. Install
```bash
cd ats-tailor
./install.sh
```

### 2. Setup LLM (choose one)

**Option A: Ollama (Free, Local)**
```bash
brew install ollama
ollama pull llama3.1:8b
ollama serve
```

**Option B: OpenAI/Claude/Gemini**
- Get API key from provider
- Enter in UI when prompted

### 3. Run
```bash
streamlit run ui/app.py
```

Open http://localhost:8501

---

## ğŸ“– Documentation

- **[SCORING_EXPLAINED.md](SCORING_EXPLAINED.md)** - How the ATS score is calculated

---

## ğŸ¯ How It Works

1. **Upload** resume (PDF/DOCX) + paste job description
2. **Analyze** - Matches requirements to your experience
3. **Review** suggestions with exact locations
4. **Apply** edits to improve your score

---

## ğŸ¤– Supported LLM Models

### Free & Local (Ollama)
- llama3.2:3b, llama3.1:8b, llama3.1:70b
- mistral, qwen2.5:7b, or any Ollama model

### Cloud-based (API key required)
- **OpenAI**: GPT-4o, GPT-4o-mini, o1-preview (~$0.002-0.02/resume)
- **Anthropic**: Claude 3.5 Sonnet, Claude 3 Opus, Claude 3 Haiku (~$0.001-0.075/resume)
- **Google**: Gemini 2.0 Flash, Gemini 1.5 Pro, Gemini 1.5 Flash (~$0.0005-0.01/resume)

**Switch models anytime in the UI sidebar** - no code changes needed!

### ğŸ”§ Adding Custom Models

**For Ollama**: Pull any model and it will appear in the dropdown
```bash
ollama pull mistral
ollama pull codellama
ollama pull your-custom-model
```

**For Cloud Providers**: Edit `ui/app.py` to add new model names to the dropdown list
```python
# Example: Add a new OpenAI model
openai_model = st.selectbox(
    "OpenAI Model",
    ["gpt-4o", "gpt-4o-mini", "your-new-model"],  # Add here
    ...
)
```

**Different use cases**:
- **Speed**: llama3.2:3b, Gemini Flash (fastest)
- **Quality**: Claude 3.5 Sonnet, GPT-4o (best suggestions)
- **Cost**: Gemini Flash, GPT-4o-mini (cheapest cloud)
- **Privacy**: Any Ollama model (100% local)
- **Reasoning**: Claude Opus, o1-preview (complex analysis)

---

## ğŸ“Š Example Output

```
ATS Score: 78/100

Coverage: 82% - Most requirements covered
Explicitness: 65% - Need to name skills more explicitly

Top Suggestions:
#1 - Experience > bullet 2 (+6 points)
    Current: Built dashboards to track performance
    Suggested: Designed A/B tests analyzing conversion lift with 
                statsmodels, improving campaign ROI by 15%
```

---

## âš™ï¸ Configuration

Edit `config.yaml`:
```yaml
models:
  llm_backend: "ollama"  # or "openai", "anthropic", "gemini"
  llm_model: "llama3.1:8b"

matching:
  tau_high: 0.75  # Similarity threshold
  tau_low: 0.50

scoring:
  coverage_weight: 0.35
  explicitness_weight: 0.25
```

---

## ğŸ› ï¸ Tech Stack

- **Parsing**: PyMuPDF, python-docx
- **NLP**: spaCy, sentence-transformers (BGE-large-en-v1.5)
- **Vector Search**: FAISS
- **LLM**: Ollama, OpenAI, Anthropic, Google AI
- **Backend**: FastAPI
- **UI**: Streamlit

---

## ğŸ“ Project Structure

```
ats-tailor/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ parsers/          # PDF/DOCX extraction
â”‚   â”œâ”€â”€ extractors/       # Resume & JD structure
â”‚   â”œâ”€â”€ matching/         # Skills matching & evidence retrieval
â”‚   â”œâ”€â”€ generation/       # LLM suggestions
â”‚   â”œâ”€â”€ scoring/          # ATS scoring
â”‚   â””â”€â”€ api/              # FastAPI endpoints
â”œâ”€â”€ ui/app.py             # Streamlit interface
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ skills_taxonomy.json  # 150+ skills
â”‚   â””â”€â”€ action_verbs.json
â””â”€â”€ config.yaml
```

---

## ğŸ“ How Scoring Works

See **[SCORING_EXPLAINED.md](SCORING_EXPLAINED.md)** for detailed explanation.

**TL;DR**: Score = weighted sum of:
- Coverage (35%) - Required skills present
- Explicitness (25%) - Skills named explicitly
- Role Alignment (15%) - Title match
- Keywords (15%) - Technical terms
- Writing Quality (10%) - Bullet structure

---

## ğŸ”’ Privacy

- âœ… All processing happens locally by default
- âœ… No data sent to external APIs (unless you choose cloud LLMs)
- âœ… No telemetry or tracking
- âœ… Open source - audit the code

---

## ğŸ“ License

MIT

---

## ğŸ™ Credits

Built with:
- BGE Embeddings (BAAI)
- Llama 3.1 (Meta)
- Ollama
- Streamlit
- FastAPI
